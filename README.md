# LLM Information-seeking and reasoning behavior  in Mastermind:
This study explores cognitive computational modeling by examining the reasoning and decision-making behaviors of Large Language Models (LLMs) in the context of the Mastermind game. By integrating human gameplay data with Bayesian network modeling, we aim to align LLM decision-making with human-like cognitive strategies, such as iterative refinement and probabilistic elimination. The Bayesian network serves as a framework for predicting optimal moves based on feedback, providing a structured guide for the LLM’s reasoning process. Fine-tuning the LLM with data from human players and Bayesian predictions enhances its ability to emulate human cognitive patterns. The model’s performance is evaluated using tailored metrics that assess alignment with human behavior, effective feedback utilization, and decision-
making efficiency. This work contributes to the broader field of cognitive computational modeling by advancing our understanding of LLM reasoning and its applicability in modeling human-like cognition in structured problem-solving tasks.

