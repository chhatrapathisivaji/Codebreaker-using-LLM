# LLM Information-seeking and reasoning behavior  in Mastermind:
This study explores cognitive computational modeling by
examining the reasoning and decision-making behaviors of

Large Language Models (LLMs) in the context of the Mas-
termind game. By integrating human gameplay data with

Bayesian network modeling, we aim to align LLM decision-
making with human-like cognitive strategies, such as itera-
tive refinement and probabilistic elimination. The Bayesian

network serves as a framework for predicting optimal moves
based on feedback, providing a structured guide for the LLM’s

reasoning process. Fine-tuning the LLM with data from hu-
man players and Bayesian predictions enhances its ability to

emulate human cognitive patterns. The model’s performance
is evaluated using tailored metrics that assess alignment with

human behavior, effective feedback utilization, and decision-
making efficiency. This work contributes to the broader field

of cognitive computational modeling by advancing our un-
derstanding of LLM reasoning and its applicability in model-
ing human-like cognition in structured problem-solving tasks.

